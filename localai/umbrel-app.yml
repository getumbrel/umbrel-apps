manifestVersion: 1
id: localai
category: ai
name: LocalAI
version: "v3.5.0"
tagline: Drop-in OpenAI replacement
description: >-
  LocalAI is the free, Open Source OpenAI alternative. LocalAI act as a drop-in replacement REST API that's compatible with OpenAI API specifications for local inferencing.
  
  
  It allows you to run LLMs, generate images, audio locally with consumer grade hardware, supporting multiple model families and architectures.


  ⚠️ Note

  Before running a model, make sure your device has enough free RAM to support it. Attempting to run a model that exceeds your available memory could cause your device to crash or become unresponsive. Always check the model requirements before downloading or starting it.
releaseNotes: >-
  This release includes several improvements and new features:
    - New backend support for MLX, including audio and visual language models
    - Added WAN support for video generation
    - New CPU and MPS version of the diffusers backend for image generation without a GPU
    - WebUI now allows downloading model configurations and manual model refresh
    - Added stop button for running backends in WebUI
    - Models can now be imported and edited via the WebUI
    - Improved Whisper backend with integrated Voice Activity Detection
    - New LocalAI Launcher App (Alpha) for easier installation and management
    - Fixed various issues related to AMD graphics cards, macOS compatibility, and CUDA detection
    - Enhanced support for macOS, including whisper, diffusers, llama.cpp, MLX, and stable-diffusion.cpp


  Full release notes can be found at https://github.com/mudler/LocalAI/releases
developer: Ettore Di Giacinto
website: https://localai.io/
dependencies: []
repo: https://github.com/mudler/LocalAI
support: https://github.com/mudler/LocalAI/discussions
port: 8793
gallery:
  - 1.jpg
  - 2.jpg
  - 3.jpg
  - 4.jpg
path: ""
defaultUsername: ""
defaultPassword: ""
submitter: highghlow
submission: https://github.com/getumbrel/umbrel-apps/pull/1079
