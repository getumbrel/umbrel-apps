manifestVersion: 1
id: localai
category: ai
name: LocalAI
version: "v2.29.0"
tagline: Drop-in OpenAI replacement
description: >-
  LocalAI is the free, Open Source OpenAI alternative. LocalAI act as a drop-in replacement REST API that's compatible with OpenAI API specifications for local inferencing.
  
  
  It allows you to run LLMs, generate images, audio locally with consumer grade hardware, supporting multiple model families and architectures.


  ⚠️ Note

  After installation, LocalAI takes a few minutes to start up. Please be patient and wait for the app to download required models.


  Also, before running a model, make sure your device has enough free RAM to support it. Attempting to run a model that exceeds your available memory could cause your device to crash or become unresponsive. Always check the model requirements before downloading or starting it.
releaseNotes: >-
  This release brings significant changes to container image tagging and contents:

    - Images with extra Python dependencies now require the '-extras' suffix
    - Default images are now slimmer without extra Python libraries
    - FFmpeg is now included in all images


  New features and improvements include:

    - Support for Qwen3 model family
    - Experimental auto GPU offload for llama.cpp and CLIP
    - GPU acceleration for Whisper.cpp (NVIDIA and Vulkan)
    - Experimental video generation endpoint
    - Uninstall option added to the installer script
    - Expanded support for AMD GPU architectures


  Full release notes can be found at https://github.com/mudler/LocalAI/releases
developer: Ettore Di Giacinto
website: https://localai.io/
dependencies: []
repo: https://github.com/mudler/LocalAI
support: https://github.com/mudler/LocalAI/discussions
port: 8793
gallery:
  - 1.jpg
  - 2.jpg
  - 3.jpg
  - 4.jpg
path: ""
defaultUsername: ""
defaultPassword: ""
submitter: highghlow
submission: https://github.com/getumbrel/umbrel-apps/pull/1079
