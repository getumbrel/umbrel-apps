manifestVersion: 1
id: localai
category: ai
name: LocalAI
version: "v3.12.1"
tagline: Drop-in OpenAI replacement
description: >-
  LocalAI is the free, Open Source OpenAI alternative. LocalAI act as a drop-in replacement REST API that's compatible with OpenAI API specifications for local inferencing.
  
  
  It allows you to run LLMs, generate images, audio locally with consumer grade hardware, supporting multiple model families and architectures.


  ⚠️ Note

  Before running a model, make sure your device has enough free RAM to support it. Attempting to run a model that exceeds your available memory could cause your device to crash or become unresponsive. Always check the model requirements before downloading or starting it.
releaseNotes: >-
  This is a patch release fixing incompatibilities with Qwen 3 Coder, along with stability improvements and minor enhancements from v3.12.0.


  Key highlights include:
    - Fixed Qwen 3 Coder incompatibilities via updated llama.cpp
    - Multi-modal Realtime - Send text, images, and audio in real-time conversations
    - Voxtral Backend - New high-quality text-to-speech backend
    - Multi-GPU Support - Improved Diffusers performance with multiple GPUs
    - Improved UI with dark/light theme variants and better navigation
    - Security fix for SSRF vulnerability in content fetching endpoints
    - Various realtime stability fixes for audio, image, and model handling


  Full release notes can be found at https://github.com/mudler/LocalAI/releases
backupIgnore:
  - data/models/*
developer: Ettore Di Giacinto
website: https://localai.io/
dependencies: []
repo: https://github.com/mudler/LocalAI
support: https://github.com/mudler/LocalAI/discussions
port: 8793
gallery:
  - 1.jpg
  - 2.jpg
  - 3.jpg
  - 4.jpg
path: ""
defaultUsername: ""
defaultPassword: ""
submitter: highghlow
submission: https://github.com/getumbrel/umbrel-apps/pull/1079
