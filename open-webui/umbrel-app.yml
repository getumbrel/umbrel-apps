manifestVersion: 1
id: open-webui
name: Open WebUI
tagline: Chat with Ollama models like DeepSeek-R1 and LLama, or use an OpenAI API key
category: ai
version: "0.5.16"
port: 2876
description: >-
  Open WebUI lets you chat with advanced AI models running locally on your own device or connect to online models using an API key.


  **Getting Started with Local AI Models:**


  🦙 Install Ollama: Start by installing the Ollama app from the Umbrel App Store. Ollama enables you to download and run large language models like Llama 3 and DeepSeek-R1 directly on your device.


  ⬇️ Download a Model: In the Open WebUI app, type the name of the model you want in the search bar and click "Pull from Ollama.com." A full list of models is available at https://ollama.com/.


  🤖 Example - Running DeepSeek-R1 1.5B: To use the DeepSeek-R1 model with 1.5 billion parameters, type deepseek-r1:1.5b in the search bar and start the download. Once it's ready, you can chat with the model directly in Open WebUI.


  ⚠️ Warning: Before running a model, make sure your device has enough free RAM to support it. Attempting to run a model that exceeds your available memory could cause your device to crash or become unresponsive. Always check the model requirements before downloading or starting it.
developer: Open WebUI
website: https://openwebui.com/
submitter: al-lac
submission: https://github.com/getumbrel/umbrel-apps/pull/1977
repo: https://github.com/open-webui/open-webui
support: https://github.com/open-webui/open-webui/issues
gallery:
  - 1.jpg
  - 2.jpg
  - 3.jpg
defaultUsername: ""
defaultPassword: ""
dependencies:
  - ollama
releaseNotes: >-
  ⚠️ If you encounter errors when chatting with your existing ollama models after this update, please clear your browser cache to resolve.
  This is a known issue with ollama and open-webui that may occur after updating.


  Highlights:
    - 📄 Full Context Mode for Local Document Search (RAG): Toggle full context mode from Admin Settings > Documents to inject entire document content into context, improving accuracy for models with large context windows—ideal for deep context understanding.
    - 🌍 Smarter Web Search with Agentic Workflows: Web searches now intelligently gather and refine multiple relevant terms, similar to RAG handling, delivering significantly better search results for more accurate information retrieval.
    - 🔎 Experimental Playwright Support for Web Loader: Web content retrieval is taken to the next level with Playwright-powered scraping for enhanced accuracy in extracted web data.
    - ☁️ Experimental Azure Storage Provider: Early-stage support for Azure Storage allows more cloud storage flexibility directly within Open WebUI.
    - 📊 Improved Jupyter Code Execution with Plots: Interactive coding now properly displays inline plots, making data visualization more seamless inside chat interactions.
    - ⏳ Adjustable Execution Timeout for Jupyter Interpreter: Customize execution timeout (default: 60s) for Jupyter-based code execution, allowing longer or more constrained execution based on your needs.
    - ▶️ "Running..." Indicator for Jupyter Code Execution: A visual indicator now appears while code execution is in progress, providing real-time status updates on ongoing computations.
    - ⚙️ General Backend & Frontend Stability Enhancements: Extensive refactoring improves reliability, performance, and overall user experience for a more seamless Open WebUI.
    - 🌍 Translation Updates: Various international translation refinements ensure better localization and a more natural user interface experience.
    - 🐞 Various bug fixes and improvements.

  Full release notes can be found at https://github.com/open-webui/open-webui/releases
path: ""
