manifestVersion: 1
id: open-webui
name: Open WebUI
tagline: Chat with Ollama models like DeepSeek-R1 and LLama, or use an OpenAI API key
category: ai
version: "0.8.5"
port: 2876
description: >-
  Open WebUI lets you chat with advanced AI models running locally on your own device or connect to online models using an API key.


  **Getting Started with Local AI Models:**


  ðŸ¦™ Install Ollama: Start by installing the Ollama app from the Umbrel App Store. Ollama enables you to download and run large language models like Llama 3 and DeepSeek-R1 directly on your device.


  â¬‡ï¸ Download a Model: In the Open WebUI app, type the name of the model you want in the search bar and click "Pull from Ollama.com." A full list of models is available at https://ollama.com/.


  ðŸ¤– Example - Running DeepSeek-R1 1.5B: To use the DeepSeek-R1 model with 1.5 billion parameters, type deepseek-r1:1.5b in the search bar and start the download. Once it's ready, you can chat with the model directly in Open WebUI.


  âš ï¸ Warning: Before running a model, make sure your device has enough free RAM to support it. Attempting to run a model that exceeds your available memory could cause your device to crash or become unresponsive. Always check the model requirements before downloading or starting it.
developer: Open WebUI
website: https://openwebui.com/
submitter: al-lac
submission: https://github.com/getumbrel/umbrel-apps/pull/1977
repo: https://github.com/open-webui/open-webui
support: https://github.com/open-webui/open-webui/issues
gallery:
  - 1.jpg
  - 2.jpg
  - 3.jpg
defaultUsername: ""
defaultPassword: ""
dependencies:
  - ollama
releaseNotes: >-
  Key highlights in this release include:
    - Voice dictation can now be toggled with a keyboard shortcut (Cmd+Shift+L or Ctrl+Shift+L)
    - Provider URL suggestions make it easier to configure connections to popular AI services
    - Individual provider connections and prompts can now be enabled or disabled without deleting them
    - Agents can now list and delete stored memories for better memory management
    - Anthropic Messages API proxy support allows tools like Claude Code to work through Open WebUI
    - Significant performance improvements across chat history loading, notes, tools, and database queries
    - Global model defaults let administrators set capabilities and parameters that apply to all models
    - Fixed model access errors that caused the models endpoint to crash with incomplete metadata
    - Fixed frontend initialization so the app loads even if individual API calls fail
    - Fixed a security vulnerability where multiple admin accounts could be created on fresh deployments
    - Fixed RAG template being repeatedly injected into messages during multiple tool calls
    - Fixed hybrid search returning empty or duplicate results
    - Fixed cyclic chat history references causing the backend to freeze
    - Fixed model fallback routing and default model selection when starting new chats
    - Fixed iframe sandbox security to prevent embedded tools from accessing same-origin content


  Full release notes are found at https://github.com/open-webui/open-webui/releases
path: ""
