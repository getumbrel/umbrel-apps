manifestVersion: 1
id: open-webui
name: Open WebUI
tagline: Chat with Ollama models like DeepSeek-R1 and LLama, or use an OpenAI API key
category: ai
version: "0.6.0"
port: 2876
description: >-
  Open WebUI lets you chat with advanced AI models running locally on your own device or connect to online models using an API key.


  **Getting Started with Local AI Models:**


  ğŸ¦™ Install Ollama: Start by installing the Ollama app from the Umbrel App Store. Ollama enables you to download and run large language models like Llama 3 and DeepSeek-R1 directly on your device.


  â¬‡ï¸ Download a Model: In the Open WebUI app, type the name of the model you want in the search bar and click "Pull from Ollama.com." A full list of models is available at https://ollama.com/.


  ğŸ¤– Example - Running DeepSeek-R1 1.5B: To use the DeepSeek-R1 model with 1.5 billion parameters, type deepseek-r1:1.5b in the search bar and start the download. Once it's ready, you can chat with the model directly in Open WebUI.


  âš ï¸ Warning: Before running a model, make sure your device has enough free RAM to support it. Attempting to run a model that exceeds your available memory could cause your device to crash or become unresponsive. Always check the model requirements before downloading or starting it.
developer: Open WebUI
website: https://openwebui.com/
submitter: al-lac
submission: https://github.com/getumbrel/umbrel-apps/pull/1977
repo: https://github.com/open-webui/open-webui
support: https://github.com/open-webui/open-webui/issues
gallery:
  - 1.jpg
  - 2.jpg
  - 3.jpg
defaultUsername: ""
defaultPassword: ""
dependencies:
  - ollama
releaseNotes: >-
  âš ï¸ If you encounter errors when chatting with your existing ollama models after this update, please clear your browser cache to resolve.
  This is a known issue with ollama and open-webui that may occur after updating.


  **Added**
    - ğŸ§© Connect external tools via OpenAPI servers.
    - ğŸ› ï¸ Expose internal MCP tools as OpenAPI servers using MCPO.
    - ğŸ“¨ Control messages asynchronously with new chat API endpoints.
    - ğŸ“ Generate PDFs client-side for improved quality.
    - ğŸ’¼ Admins can enforce temporary chats for compliance.
    - ğŸŒ Fine-grained permissions for public resource sharing.
    - ğŸ“¦ Set custom pip options for tool/function installations.
    - ğŸ”¢ Double-click message count to edit index quickly.
    - ğŸ§  Add custom prefixes to embeddings for better RAG.
    - ğŸ™ˆ Optionally hide base models from the UI.
    - ğŸ“š Use Docling for enhanced content extraction from files.
    - ğŸ—ƒï¸ Added Redis Sentinel support for high availability.
    - ğŸ“š Support JSON schema format definition in Ollama models.
    - ğŸ” Clear button added to chat sidebar search.
    - ğŸ—‚ï¸ Auto-focus and Enter submit for new folder renaming.
    - ğŸ§± Render styled Markdown alert banners from blockquotes.
    - ğŸ” Hybrid search components now run in parallel for speed.
    - ğŸ“‹ Cleaner UI display for tool calls in chat messages.
    - ğŸ§ª Playwright timeout is now configurable.
    - ğŸ“ˆ Integrated OpenTelemetry for observability (opt-in, self-hosted).
    - ğŸ›  General UI enhancements and UX polish implemented.
    - ğŸ§± Backend refactored for improved stability and performance.
    - ğŸŒ Added/updated languages: Estonian, Galician, Spanish, Chinese, Turkish, etc.

  **Fixed**
    - ğŸ§‘â€ğŸ’» Corrected text input height bug in Firefox.
    - ğŸ§¾ Fixed Tika adding excessive blank lines in processed PDFs.
    - ğŸ§ª Resolved CSV loader encoding issues by auto-detecting charsets.
    - âœ… Made certificate path optional for LDAP authentication setup.
    - ğŸ“¥ Fixed file deletion issue in bypass embedding mode.
    - ğŸ§© Corrected RAG hybrid/reranker citation, sorting, and deduplication.
    - ğŸ§· Fixed bug preventing single model export/import.
    - ğŸ“« Resolved unnecessary login prompts for already authenticated users.


  Full release notes can be found at https://github.com/open-webui/open-webui/releases
path: ""
