manifestVersion: 1
id: open-webui
name: Open WebUI
tagline: Chat with Ollama models like DeepSeek-R1 and LLama, or use an OpenAI API key
category: ai
version: "0.6.0"
port: 2876
description: >-
  Open WebUI lets you chat with advanced AI models running locally on your own device or connect to online models using an API key.


  **Getting Started with Local AI Models:**


  🦙 Install Ollama: Start by installing the Ollama app from the Umbrel App Store. Ollama enables you to download and run large language models like Llama 3 and DeepSeek-R1 directly on your device.


  ⬇️ Download a Model: In the Open WebUI app, type the name of the model you want in the search bar and click "Pull from Ollama.com." A full list of models is available at https://ollama.com/.


  🤖 Example - Running DeepSeek-R1 1.5B: To use the DeepSeek-R1 model with 1.5 billion parameters, type deepseek-r1:1.5b in the search bar and start the download. Once it's ready, you can chat with the model directly in Open WebUI.


  ⚠️ Warning: Before running a model, make sure your device has enough free RAM to support it. Attempting to run a model that exceeds your available memory could cause your device to crash or become unresponsive. Always check the model requirements before downloading or starting it.
developer: Open WebUI
website: https://openwebui.com/
submitter: al-lac
submission: https://github.com/getumbrel/umbrel-apps/pull/1977
repo: https://github.com/open-webui/open-webui
support: https://github.com/open-webui/open-webui/issues
gallery:
  - 1.jpg
  - 2.jpg
  - 3.jpg
defaultUsername: ""
defaultPassword: ""
dependencies:
  - ollama
releaseNotes: >-
  ⚠️ If you encounter errors when chatting with your existing ollama models after this update, please clear your browser cache to resolve.
  This is a known issue with ollama and open-webui that may occur after updating.


  **Added**
    - 🧩 Connect external tools via OpenAPI servers.
    - 🛠️ Expose internal MCP tools as OpenAPI servers using MCPO.
    - 📨 Control messages asynchronously with new chat API endpoints.
    - 📝 Generate PDFs client-side for improved quality.
    - 💼 Admins can enforce temporary chats for compliance.
    - 🌍 Fine-grained permissions for public resource sharing.
    - 📦 Set custom pip options for tool/function installations.
    - 🔢 Double-click message count to edit index quickly.
    - 🧠 Add custom prefixes to embeddings for better RAG.
    - 🙈 Optionally hide base models from the UI.
    - 📚 Use Docling for enhanced content extraction from files.
    - 🗃️ Added Redis Sentinel support for high availability.
    - 📚 Support JSON schema format definition in Ollama models.
    - 🔍 Clear button added to chat sidebar search.
    - 🗂️ Auto-focus and Enter submit for new folder renaming.
    - 🧱 Render styled Markdown alert banners from blockquotes.
    - 🔁 Hybrid search components now run in parallel for speed.
    - 📋 Cleaner UI display for tool calls in chat messages.
    - 🧪 Playwright timeout is now configurable.
    - 📈 Integrated OpenTelemetry for observability (opt-in, self-hosted).
    - 🛠 General UI enhancements and UX polish implemented.
    - 🧱 Backend refactored for improved stability and performance.
    - 🌍 Added/updated languages: Estonian, Galician, Spanish, Chinese, Turkish, etc.

  **Fixed**
    - 🧑‍💻 Corrected text input height bug in Firefox.
    - 🧾 Fixed Tika adding excessive blank lines in processed PDFs.
    - 🧪 Resolved CSV loader encoding issues by auto-detecting charsets.
    - ✅ Made certificate path optional for LDAP authentication setup.
    - 📥 Fixed file deletion issue in bypass embedding mode.
    - 🧩 Corrected RAG hybrid/reranker citation, sorting, and deduplication.
    - 🧷 Fixed bug preventing single model export/import.
    - 📫 Resolved unnecessary login prompts for already authenticated users.


  Full release notes can be found at https://github.com/open-webui/open-webui/releases
path: ""
